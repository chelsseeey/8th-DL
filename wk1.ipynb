{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 다루기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], device='mps:0')\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import torch\n",
    "print(torch.tensor([[1,2],[3,4]]))\n",
    "print(torch.tensor([[1,2],[3,4]], device='cuda:0'))\n",
    "print(torch.tensor([[1,2],[3,4]], device='cuda:0', dtype=torch.float64))\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "# 기본 CPU 텐서\n",
    "print(torch.tensor([[1, 2], [3, 4]]))\n",
    "\n",
    "# MPS(Apple Metal) 디바이스 텐서\n",
    "print(torch.tensor([[1, 2], [3, 4]], device='mps'))\n",
    "\n",
    "# MPS 디바이스 텐서 + float32 dtype\n",
    "print(torch.tensor([[1, 2], [3, 4]], device='mps', dtype=torch.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 버전: 2.5.1\n",
      "CUDA 사용 가능 여부: False\n",
      "GPU 개수: 0\n",
      "현재 사용 중인 GPU: GPU 사용 불가\n",
      "GPU 이름: GPU 사용 불가\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch 버전:\", torch.__version__)\n",
    "print(\"CUDA 사용 가능 여부:\", torch.cuda.is_available())\n",
    "print(\"GPU 개수:\", torch.cuda.device_count())\n",
    "print(\"현재 사용 중인 GPU:\", torch.cuda.current_device() if torch.cuda.is_available() else \"GPU 사용 불가\")\n",
    "print(\"GPU 이름:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"GPU 사용 불가\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "temp=torch.tensor([[1,2],[3,4]])\n",
    "print(temp.numpy()) \n",
    "temp=torch.tensor([[1,2],[3,4]], device='mps')\n",
    "print(temp.to('cpu').numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) tensor(2.) tensor(7.)\n",
      "------------------------\n",
      "tensor([3., 4., 5.]) tensor([5., 6.])\n"
     ]
    }
   ],
   "source": [
    "temp=torch.FloatTensor([1,2,3,4,5,6,7])\n",
    "print(temp[0],temp[1],temp[-1])\n",
    "print('------------------------')\n",
    "print(temp[2:5],temp[4:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "v=torch.tensor([1,2,3])\n",
    "w=torch.tensor([3,4,6])\n",
    "print(w-v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "------------------------\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "------------------------\n",
      "tensor([1, 2, 3, 4])\n",
      "------------------------\n",
      "tensor([[1, 2, 3, 4]])\n",
      "------------------------\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "#텐서의 차원을 조작\n",
    "temp=torch.tensor([[1,2],[3,4]])\n",
    "\n",
    "print(temp.shape)\n",
    "print('------------------------')\n",
    "print(temp.view(4,1))\n",
    "print('------------------------')\n",
    "print(temp.view(-1))\n",
    "print('------------------------')\n",
    "print(temp.view(1,-1))  #-1은 (1,?)과 같은 의미\n",
    "print('------------------------')\n",
    "print(temp.view(-1,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch \n",
    "data=pd.read_csv('../class2.csv')\n",
    "\n",
    "x=torch.from_numpy(data['x'].values).unsqueeze(dim=1).float()\n",
    "y=torch.from_numpy(data['y'].values).unsqueeze(dim=1).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "custom dataset : 데이터를 한번에 다 부르지 않고 조금씩 나누어 불러서 사용하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "    def __len__(self):\n",
    "    def __getitem__(self,index):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.label=pd.read_csv(csv_file)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        sample=torch.tensor(self.label.iloc[idx,0:3]).int()\n",
    "        label=torch.tensor(self.label.iloc[idx,3]).int()\n",
    "        return sample,label\n",
    "tensor_dataset=CustomDataset('../covtype.csv')\n",
    "tensor_loader=DataLoader(tensor_dataset,batch_size=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "mnist_transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(1.0,))\n",
    "])\n",
    "from torchvision.datasets import MNIST\n",
    "import requests\n",
    "download_root='../chap02/data/MNIST_DATASET'\n",
    "train_dataset=MNIST(download_root,train=True,transform=mnist_transform,download=True)\n",
    "valid_dataset=MNIST(download_root,train=False,transform=mnist_transform,download=True)\n",
    "test_dataset=MNIST(download_root,train=False,transform=mnist_transform,download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=nn.Linear(in_features=1, out_features=1, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing children\n",
      "-------------------\n",
      "[Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Sequential(\n",
      "  (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=750, out_features=10, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      ")]\n",
      "\n",
      "\n",
      "Printing modules\n",
      "-------------------\n",
      "[MLP(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Linear(in_features=750, out_features=10, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Sequential(\n",
      "  (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Sequential(\n",
      "  (0): Linear(in_features=750, out_features=10, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "), Linear(in_features=750, out_features=10, bias=True), ReLU(inplace=True)]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP,self).__init__()\n",
    "        self.layer1=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layer2=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=30, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layer3=nn.Sequential(\n",
    "            nn.Linear(in_features=30*5*5, out_features=10, bias=True),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        def forward(self,x):\n",
    "            x=self.layer1(x)\n",
    "            x=self.layer2(x)\n",
    "            x=x.view(x.size(0),-1)\n",
    "            x=self.layer3(x)\n",
    "            return x\n",
    "model=MLP()\n",
    "\n",
    "print('Printing children\\n-------------------')\n",
    "print(list(model.children()))\n",
    "print('\\n\\nPrinting modules\\n-------------------')\n",
    "print(list(model.modules()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(in_features=1, hidden_features=1, out_features=1):\n",
    "    hidden=nn.Linear(in_features, out_features=hidden_features, bias=True)\n",
    "    activation=nn.ReLU()\n",
    "    output=nn.Linear(hidden_features, out_features, bias=True)\n",
    "    net=nn.Sequential(hidden,activation,output)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 0.95**epoch)\n",
    "\n",
    "for epoch in range(1, 100+1):\n",
    "    for x, y in DataLoader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(x), y)  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    yhat=model(x_train)\n",
    "    loss=criterion(yhat,y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchmetrics\n",
    "preds=torch.randn(10,5).softmax(dim=1)\n",
    "target=torch.randint(0,5,(10,))\n",
    "acc=torchmetrics.functional.accuracy(preds,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "metric=torchmetrics.Accuracy()\n",
    "\n",
    "n_batches=10\n",
    "for i in range(n_batches):\n",
    "    preds=torch.randn(10,5).softmax(dim=-1)\n",
    "    target=torch.randint(5,(10,))\n",
    "    \n",
    "    acc=metric(preds,target)\n",
    "    print(f\"Accuray on batch {i}: {acc}\")\n",
    "acc=metric.compute()\n",
    "print(f\"Final accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 과정 모니터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer=SummaryWriter(\"../chap02/tensorboard\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    batch_loss=0.0\n",
    "    \n",
    "    for i, (x,y) in enumerate(dataloader):\n",
    "        x,y=x.to(device).float(),y.to(device).float()\n",
    "        outputs=model(x)\n",
    "        loss=criterion(outputs,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model.train() & model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    valid_loss=0\n",
    "    \n",
    "    for x,y in valid_dataloader:\n",
    "        outputs=model(x)\n",
    "        loss=F.cross_entropy(outputs,y.long().squeeze())\n",
    "        valid_loss+=float(loss)\n",
    "        y_hat+=[outputs]\n",
    "        \n",
    "valid_loss=valid_loss/len(valid_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이토치 코드 맛보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_capacity</th>\n",
       "      <th>safety</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  maint doors persons lug_capacity safety output\n",
       "0  vhigh  vhigh     2       2        small    low  unacc\n",
       "1  vhigh  vhigh     2       2        small    med  unacc\n",
       "2  vhigh  vhigh     2       2        small   high  unacc\n",
       "3  vhigh  vhigh     2       2          med    low  unacc\n",
       "4  vhigh  vhigh     2       2          med    med  unacc"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "dataset=pd.read_csv('car_evaluation.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='count'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig_size=plt.rcParams['figure.figsize']\n",
    "fig_size[0]=8\n",
    "fig_size[1]=6\n",
    "plt.rcParams['figure.figsize']=fig_size\n",
    "dataset.output.value_counts().plot(kind='pie',autopct='%0.05f%%',\n",
    "                                    colors=['lightblue','lightgreen','orange','pink'],explode=(0.05,0.05,0.05,0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 0, 0, 2, 1],\n",
       "       [3, 3, 0, 0, 2, 2],\n",
       "       [3, 3, 0, 0, 2, 0],\n",
       "       [3, 3, 0, 0, 1, 1],\n",
       "       [3, 3, 0, 0, 1, 2],\n",
       "       [3, 3, 0, 0, 1, 0],\n",
       "       [3, 3, 0, 0, 0, 1],\n",
       "       [3, 3, 0, 0, 0, 2],\n",
       "       [3, 3, 0, 0, 0, 0],\n",
       "       [3, 3, 0, 1, 2, 1]], dtype=int8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예제 데이터셋 칼럼들의 목록\n",
    "categorial_columns=['price','maint','doors','persons','lug_capacity','safety']\n",
    "\n",
    "#astype() 메서드를 이ㅛㅇ하여 데이터를 범주형으로 변환\n",
    "for category in categorial_columns:\n",
    "    dataset[category]=dataset[category].astype('category')\n",
    "    \n",
    "price=dataset['price'].cat.codes.values\n",
    "maint=dataset['maint'].cat.codes.values\n",
    "doors=dataset['doors'].cat.codes.values\n",
    "\n",
    "persons=dataset['persons'].cat.codes.values\n",
    "lug_capacity=dataset['lug_capacity'].cat.codes.values\n",
    "safety=dataset['safety'].cat.codes.values\n",
    "\n",
    "catagorical_data=np.stack([price,maint,doors,persons,lug_capacity,safety],1)\n",
    "catagorical_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1728, 6)\n",
      "torch.Size([6912])\n"
     ]
    }
   ],
   "source": [
    "outputs=pd.get_dummies(dataset.output)\n",
    "outputs=outputs.values\n",
    "outputs=torch.tensor(outputs).flatten()\n",
    "\n",
    "print(catagorical_data.shape)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>weight</th>\n",
       "      <th>nation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>72</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>55</td>\n",
       "      <td>Korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>58</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  weight     nation\n",
       "0    male      72      Japan\n",
       "1  female      55      Korea\n",
       "2    male      58  Australia"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data={\n",
    "    'gender':['male','female','male'],\n",
    "    'weight':[72,55,58],\n",
    "    'nation':['Japan','Korea','Australia']\n",
    "}\n",
    "\n",
    "df=pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>nation_Australia</th>\n",
       "      <th>nation_Japan</th>\n",
       "      <th>nation_Korea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight  gender_female  gender_male  nation_Australia  nation_Japan  \\\n",
       "0      72          False         True             False          True   \n",
       "1      55           True        False             False         False   \n",
       "2      58          False         True              True         False   \n",
       "\n",
       "   nation_Korea  \n",
       "0         False  \n",
       "1          True  \n",
       "2         False  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "a=np.array([[1,2],[3,4]])\n",
    "print(a.ravel())\n",
    "print(a.reshape(-1))\n",
    "print(a.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 2), (4, 2), (4, 2), (3, 2), (3, 2), (3, 2)]\n"
     ]
    }
   ],
   "source": [
    "categorical_column_sizes=[len(dataset[column].cat.categories) for column in categorial_columns]\n",
    "categorical_embedding_sizes=[(col_size,min(50,(col_size+1)//2)) for col_size in categorical_column_sizes]\n",
    "print(categorical_embedding_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_records=1728\n",
    "test_records=int(total_records*0.2)\n",
    "\n",
    "catagorical_train_data=catagorical_data[:total_records-test_records]\n",
    "catagorical_test_data=catagorical_data[total_records-test_records:total_records]\n",
    "train_outputs=outputs[:total_records-test_records]\n",
    "test_outputs=outputs[total_records-test_records:total_records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383\n",
      "1383\n",
      "345\n",
      "345\n"
     ]
    }
   ],
   "source": [
    "print(len(catagorical_train_data))\n",
    "print(len(train_outputs))\n",
    "print(len(catagorical_test_data))\n",
    "print(len(test_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,embedding_size,output_size, layers, p=0.4):\n",
    "        super().__init__()\n",
    "        self.all_embeddings=nn.ModuleList([nn.Embedding(ni,nf) for ni,nf in embedding_size])\n",
    "        self.embedding_dropout=nn.Dropout(p)\n",
    "        \n",
    "        all_layers=[]\n",
    "        num_categorical_cols=sum((nf for ni,nf in embedding_size))\n",
    "        input_size=num_categorical_cols\n",
    "        for i in layers:\n",
    "            all_layers.append(nn.Linear(input_size,i))\n",
    "            all_layers.append(nn.ReLU(inplace=True))\n",
    "            all_layers.append(nn.BatchNorm1d(i))\n",
    "            all_layers.append(nn.Dropout(p))\n",
    "            input_size=i\n",
    "            \n",
    "        all_layers.append(nn.Linear(layers[-1],output_size))\n",
    "        self.layers=nn.Sequential(*all_layers)\n",
    "        \n",
    "    def forward(self,x_categorical):\n",
    "        embeddings=[]\n",
    "        for i,e in enumerate(self.all_embeddings):\n",
    "            embeddings.append(e(x_categorical[:,i]))\n",
    "        x=torch.cat(embeddings,1)\n",
    "        x=self.embedding_dropout(x)\n",
    "        x=self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (all_embeddings): ModuleList(\n",
      "    (0-2): 3 x Embedding(4, 2)\n",
      "    (3-5): 3 x Embedding(3, 2)\n",
      "  )\n",
      "  (embedding_dropout): Dropout(p=0.4, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=200, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.4, inplace=False)\n",
      "    (8): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.4, inplace=False)\n",
      "    (12): Linear(in_features=50, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=Model(categorical_embedding_sizes,4,[200,100,50],p=0.4)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7p/npc42ml14hsdz2qfn43lc51m0000gn/T/ipykernel_74464/2731399717.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  catagorical_train_data = torch.tensor(catagorical_train_data, dtype=torch.long, device=device)\n",
      "/var/folders/7p/npc42ml14hsdz2qfn43lc51m0000gn/T/ipykernel_74464/2731399717.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_outputs = torch.tensor(train_outputs, dtype=torch.long, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: 1.60019720\n",
      "epoch:  26 loss: 1.41587591\n",
      "epoch:  51 loss: 1.30578458\n",
      "epoch:  76 loss: 1.19392371\n",
      "epoch: 101 loss: 1.08023822\n",
      "epoch: 126 loss: 0.93049651\n",
      "epoch: 151 loss: 0.82374090\n",
      "epoch: 176 loss: 0.73694879\n",
      "epoch: 201 loss: 0.70405132\n",
      "epoch: 226 loss: 0.66560006\n",
      "epoch: 251 loss: 0.64449430\n",
      "epoch: 276 loss: 0.62348288\n",
      "epoch: 301 loss: 0.60305870\n",
      "epoch: 326 loss: 0.60607475\n",
      "epoch: 351 loss: 0.59729302\n",
      "epoch: 376 loss: 0.59649140\n",
      "epoch: 401 loss: 0.58034122\n",
      "epoch: 426 loss: 0.57848531\n",
      "epoch: 451 loss: 0.57330346\n",
      "epoch: 476 loss: 0.58233160\n",
      "epoch: 500 loss: 0.5781533122\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 예: device 설정 (Apple Silicon(M1/M2/M3) 환경이면 \"mps\", 아니면 \"cuda\" 또는 \"cpu\")\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# 모델을 device로 이동\n",
    "model = model.to(device)\n",
    "\n",
    "# 데이터를 텐서로 변환 후 device에 올림 (dtype은 임베딩 등에서 long 필요)\n",
    "catagorical_train_data = torch.tensor(catagorical_train_data, dtype=torch.long, device=device)\n",
    "train_outputs = torch.tensor(train_outputs, dtype=torch.long, device=device)\n",
    "\n",
    "epochs = 500\n",
    "aggregated_losses = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # 순전파(Forward)\n",
    "    y_pred = model(catagorical_train_data)\n",
    "    single_loss = loss_function(y_pred, train_outputs)\n",
    "    \n",
    "    # 손실값 저장 (item()으로 파이썬 float 추출)\n",
    "    aggregated_losses.append(single_loss.item())\n",
    "    \n",
    "    # 일정 간격으로 학습 상황 출력\n",
    "    if epoch % 25 == 1:\n",
    "        print(f\"epoch: {epoch:3d} loss: {single_loss.item():10.8f}\")\n",
    "    \n",
    "    # 역전파(Backward) 및 최적화(Optimization)\n",
    "    optimizer.zero_grad()\n",
    "    single_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# 최종 에폭 결과 출력\n",
    "print(f\"epoch: {epoch:3d} loss: {single_loss.item():10.10f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.56123626\n"
     ]
    }
   ],
   "source": [
    "# catagorical_test_data를 LongTensor로 변환\n",
    "catagorical_test_data = torch.tensor(catagorical_test_data, dtype=torch.long, device=device)\n",
    "\n",
    "test_outputs = test_outputs.to(device=device, dtype=torch.int64)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_val = model(catagorical_test_data)  # 이제 오류 없이 텐서로 입력\n",
    "    loss = loss_function(y_val, test_outputs)\n",
    "print(f'Loss: {loss:.8f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.3719,  2.1440, -3.7218, -3.7182],\n",
      "        [ 1.7963,  1.0036, -2.3565, -2.1838],\n",
      "        [ 2.3649,  1.5639, -3.3986, -3.6514],\n",
      "        [ 2.7980,  1.4888, -3.0753, -3.3044],\n",
      "        [ 1.6430,  0.9629, -2.0581, -2.2644]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(y_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# y_val이 mps 텐서라면:\n",
    "y_val_argmax = y_val.argmax(dim=1)  # axis=1에 해당\n",
    "print(y_val_argmax[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[259   0]\n",
      " [ 86   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       259\n",
      "           1       0.00      0.00      0.00        86\n",
      "\n",
      "    accuracy                           0.75       345\n",
      "   macro avg       0.38      0.50      0.43       345\n",
      "weighted avg       0.56      0.75      0.64       345\n",
      "\n",
      "0.7507246376811594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "print(confusion_matrix(test_outputs.cpu(),y_val_argmax.cpu()))\n",
    "print(classification_report(test_outputs.cpu(),y_val_argmax.cpu()))\n",
    "print(accuracy_score(test_outputs.cpu(),y_val_argmax.cpu()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
